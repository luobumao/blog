---
icon: pen-to-square
date: 2025-07-23
category:
  - åŸåˆ›
  - æ’ä»¶
tag:
  - Python
---
# Pagermaidæ’ä»¶è°ƒç”¨Gemini(å¾…å®Œå–„)
ç”¨äºä½¿ç”¨Geminiå®ç°é—®ç­”ã€æ¨¡å‹åˆ‡æ¢ã€é»˜è®¤æç¤ºè¯è®¾ç½®å’Œå›¾åƒè¯†åˆ«åŠŸèƒ½çš„äººå½¢è‡ªèµ°æœºå™¨äººæ’ä»¶ã€‚
<!-- more -->
## è„šæœ¬åŠŸèƒ½
,gemini setapi <ä½ çš„APIå¯†é’¥> - è®¾ç½®æ‚¨çš„ Google AI API å¯†é’¥

,gemini setmodel <æ¨¡å‹åç§°> - åˆ‡æ¢ä½¿ç”¨çš„ Gemini æ¨¡å‹

,gemini prompt <æç¤ºè¯> - è®¾ç½®è‡ªå®šä¹‰çš„åŸºç¡€æç¤ºè¯ï¼ˆç•™ç©ºåˆ™é‡ç½®ï¼‰

,gemini list - æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹

,gemini <ä½ çš„é—®é¢˜> - ä¸ Gemini å¯¹è¯ (å¯å›å¤å›¾ç‰‡)

## æ’ä»¶ä»£ç 
```
import json
import os
import sys
import subprocess
from io import BytesIO

from pagermaid.enums import Client, Message
from pagermaid.listener import listener
from pagermaid.utils import pip_install

def install_dependencies():
    dependencies = {
        "google.generativeai": "google-generativeai>=0.5.0",
        "PIL": "Pillow"
    }
    for import_name, package_name in dependencies.items():
        try:
            __import__(import_name.split('.')[0])
        except ImportError:
            print(f"æ­£åœ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–: {package_name}...")
            python_executable = sys.executable
            command = [python_executable, "-m", "pip", "install", package_name]
            try:
                subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            except subprocess.CalledProcessError as e:
                print("======================== è­¦å‘Š ========================")
                print(f"è‡ªåŠ¨å®‰è£…ä¾èµ– '{package_name}' å¤±è´¥ã€‚")
                print("è¯·é€šè¿‡SSHè¿æ¥åˆ°æ‚¨çš„æœåŠ¡å™¨ï¼Œå¹¶æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
                print(f"'{python_executable} -m pip install {package_name}'")
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {e.stderr.decode('utf-8', errors='ignore')}")
                print("======================================================")

install_dependencies()

try:
    import google.generativeai as genai
    from PIL import Image
except ImportError as e:
    print(f"å…³é”®ä¾èµ–å¯¼å…¥å¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥ä¸Šè¿°å®‰è£…æ—¥å¿—å¹¶æ‰‹åŠ¨è§£å†³ã€‚")
    pass

CONFIG_FILE_PATH = "gemini_config.json"

def load_gemini_config():
    if not os.path.exists(CONFIG_FILE_PATH):
        return {}
    try:
        with open(CONFIG_FILE_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError):
        return {}

def save_gemini_config(data):
    try:
        with open(CONFIG_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except IOError:
        pass

@listener(
    command="gemini",
    description="ä¸ Google Gemini å¯¹è¯ï¼Œæˆ–è¿›è¡Œè®¾ç½®ã€‚",
    parameters=(
        "\n- `,gemini setapi <ä½ çš„APIå¯†é’¥>` - è®¾ç½®æ‚¨çš„ Google AI API å¯†é’¥"
        "\n- `,gemini setmodel <æ¨¡å‹åç§°>` - åˆ‡æ¢ä½¿ç”¨çš„ Gemini æ¨¡å‹"
        "\n- `,gemini prompt <æç¤ºè¯>` - è®¾ç½®è‡ªå®šä¹‰çš„åŸºç¡€æç¤ºè¯ï¼ˆç•™ç©ºåˆ™é‡ç½®ï¼‰"
        "\n- `,gemini list` - æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"
        "\n- `,gemini <ä½ çš„é—®é¢˜>` - ä¸ Gemini å¯¹è¯ (å¯å›å¤å›¾ç‰‡)"
    )
)
async def gemini_chat(client: Client, message: Message):
    opt = message.arguments.strip()
    args = opt.split()
    command = args[0].lower() if args else ""

    # Sub-command handling
    if command == "setapi":
        if len(args) > 1:
            api_key = " ".join(args[1:])
            config = load_gemini_config()
            config['api_key'] = api_key
            save_gemini_config(config)
            return await message.edit(f"âœ… **Gemini API å¯†é’¥å·²è®¾ç½®æˆåŠŸï¼**\n"
                                      f"éƒ¨åˆ†å¯†é’¥ï¼š`{api_key[:5]}...{api_key[-4:]}`")
        else:
            return await message.edit("âŒ `setapi` å‘½ä»¤éœ€è¦ä¸€ä¸ª API å¯†é’¥ä½œä¸ºå‚æ•°ã€‚")

    elif command == "setmodel":
        if len(args) > 1:
            model_name = args[1]
            config = load_gemini_config()
            config['model'] = model_name
            save_gemini_config(config)
            return await message.edit(f"âœ… **Gemini æ¨¡å‹å·²è®¾ç½®ä¸º:** `{model_name}`")
        else:
            return await message.edit("âŒ `setmodel` å‘½ä»¤éœ€è¦ä¸€ä¸ªæ¨¡å‹åç§°ä½œä¸ºå‚æ•°ã€‚")
            
    elif command == "prompt":
        if len(args) > 1:
            base_prompt_text = " ".join(args[1:])
            config = load_gemini_config()
            config['base_prompt'] = base_prompt_text
            save_gemini_config(config)
            return await message.edit(f"âœ… **åŸºç¡€ Prompt å·²æ›´æ–°ä¸º:**\n`{base_prompt_text}`")
        else:
            config = load_gemini_config()
            if config.pop('base_prompt', None) is not None:
                save_gemini_config(config)
                await message.edit("âœ… **åŸºç¡€ Prompt å·²æˆåŠŸé‡ç½®ä¸ºé»˜è®¤å€¼ã€‚**")
            else:
                await message.edit("â„¹ï¸ **åŸºç¡€ Prompt å½“å‰å·²æ˜¯é»˜è®¤å€¼ï¼Œæ— éœ€é‡ç½®ã€‚**")
            return

    elif command == "list":
        models = [
            "gemini-2.5-pro", "gemini-2.5-flash", "gemini-2.0-flash",
            "gemini-2.0-flash-lite", "gemini-1.5-flash", "gemini-1.5-flash-8b",
            "gemini-1.5-pro"
        ]
        config = load_gemini_config()
        current_model = config.get('model', 'gemini-2.5-pro')
        response_text = "**å¯ç”¨çš„ Gemini æ¨¡å‹åˆ—è¡¨:**\n\n"
        for model in models:
            if model == current_model:
                response_text += f"`{model}` **(å½“å‰ä½¿ç”¨)**\n"
            else:
                response_text += f"`{model}`\n"
        response_text += "\nä½¿ç”¨ `,gemini setmodel <æ¨¡å‹åç§°>` æ¥åˆ‡æ¢æ¨¡å‹ã€‚"
        return await message.edit(response_text)

    # Main chat logic
    else:
        config = load_gemini_config()
        api_key = config.get('api_key')
        model_name = config.get('model', 'gemini-2.5-pro')
        base_prompt = config.get('base_prompt', 'å§‹ç»ˆä½¿ç”¨ä¸­æ–‡äº¤æµã€‚å¦‚æœè¾“å‡ºä¸å«ä»£ç ï¼Œè¯·å°†æ‰€æœ‰å†…å®¹ä½¿ç”¨ Markdown å¼•ç”¨æ ¼å¼ï¼ˆ\'>\'ï¼‰ï¼›å¦‚æœè¾“å‡ºå«æœ‰ä»£ç ï¼Œåˆ™ä»…å°†ä»£ç éƒ¨åˆ†ä½¿ç”¨ Markdown ä»£ç å—æ ¼å¼åŒ–ï¼Œæ­£æ–‡éƒ¨åˆ†ä¸ä½¿ç”¨ä»»ä½•æ ¼å¼ã€‚')

        if not api_key:
            return await message.edit("âŒ **æœªé…ç½® Gemini API å¯†é’¥ã€‚**\n\nè¯·ä½¿ç”¨ `,gemini setapi <ä½ çš„å¯†é’¥>` è¿›è¡Œé…ç½®ã€‚")

        try:
            genai.configure(api_key=api_key)
        except Exception as e:
            return await message.edit(f"API å¯†é’¥é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ï¼š`{e}`")

        await message.edit(f"ğŸ§  æ¨¡å‹ `{model_name}` æ€è€ƒä¸­...")

        target_message = message.reply_to_message or message
        
        prompt_parts_for_ai = []
        if message.reply_to_message and (message.reply_to_message.text or message.reply_to_message.caption):
            replied_text = message.reply_to_message.text or message.reply_to_message.caption
            prompt_parts_for_ai.append(replied_text)
        if opt:
            prompt_parts_for_ai.append(opt)
        prompt_for_ai = "\n\n".join(prompt_parts_for_ai)
        
        image = None
        if target_message.photo or (target_message.document and target_message.document.mime_type.startswith("image/")):
            try:
                file_io = await client.download_media(target_message, in_memory=True)
                file_io.seek(0)
                image = Image.open(file_io)
            except Exception as e:
                return await message.edit(f"ğŸ–¼ï¸ **å›¾ç‰‡å¤„ç†å¤±è´¥**\n\n**åŸå§‹é”™è¯¯:**\n`{e}`")

        if not prompt_for_ai and not image:
            return await message.edit("ğŸ¤” è¯·è¾“å…¥é—®é¢˜æˆ–å›å¤ä¸€æ¡æ¶ˆæ¯/å›¾ç‰‡ã€‚")

        full_prompt_for_ai = base_prompt
        if base_prompt and prompt_for_ai.strip():
            full_prompt_for_ai += f"\n\nç”¨æˆ·é—®é¢˜ï¼š\n{prompt_for_ai.strip()}"
        elif not base_prompt and prompt_for_ai.strip():
            full_prompt_for_ai = prompt_for_ai.strip()

        try:
            model = genai.GenerativeModel(model_name)
            contents = [p for p in (full_prompt_for_ai, image) if p]
            response = await model.generate_content_async(contents)

            if not response.parts:
                if response.prompt_feedback and response.prompt_feedback.block_reason:
                    return await message.edit(f"âš ï¸ è¯·æ±‚è¢«é˜»æ­¢ï¼ŒåŸå› ï¼š`{response.prompt_feedback.block_reason.name}`")
                else:
                    return await message.edit("âŒ Gemini æœªè¿”å›ä»»ä½•å†…å®¹ã€‚")
            
            question_for_display = opt
            answer_text = response.text

            if question_for_display:
                processed_question = '> ' + question_for_display.replace('\n', '\n> ')
                final_text = (
                    f"**ğŸ¤” é—®é¢˜:**\n{processed_question}\n\n"
                    f"**ğŸ¤– Gemini çš„å›ç­”:**\n{answer_text}"
                )
            else:
                final_text = f"**ğŸ¤– Gemini çš„å›ç­”:**\n{answer_text}"

            await message.edit(final_text)
            
        except Exception as e:
            await message.edit(f"ğŸ¤– **Gemini API è°ƒç”¨å¤±è´¥**\n\n**é”™è¯¯ä¿¡æ¯:**\n`{e}`\n\nè¯·æ£€æŸ¥æ‚¨çš„ API å¯†é’¥ã€æ¨¡å‹åç§° (`{model_name}`) æ˜¯å¦æœ‰æ•ˆæˆ–è´¦æˆ·ä½™é¢æ˜¯å¦å……è¶³ã€‚")
```

